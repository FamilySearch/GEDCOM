import re
import typing

verbose:bool = False


def tidy_markdown(md, indent, width=79):
    r"""
    The markdown files in the specification directory use the following Markdown dialect:
    
    Part of GFM:

    - setext headers with classes like `{.unnumbered}`, unlisting marks like `{-}`, and anchors like `{#container}`
    - language-specific code blocks both <code>\`\`\`gedcom</code> and <code>\`\`\` {.gedstruct .long}</code> headers
    - markdown inside HTML between lines `<div class="example">` and `</div>` (only inside lists) and between definition list tags `<dl>`, `<dt>`, and `<dd>` (only in acknowledgements)
    - code blocks with no leading blank line
    - tables with `|---|:--|` format
    - tables with `--- | --- | ---` format
    
    Not part of GFM:

    - YAML front matter
    - divs with `:::class` headers and `:::` footers
    - automatic links with `[name of section to link to]`
    - inline code with class `1 NO MARR`{.gedcom} (used only once)
    
    pip install mdformat-gfm
    """
    for k,v in pfx.items():
      md = re.sub(rf'\b{k}', v, md)
    
    # ignoring YAML frontmatter
    md = re.sub(r':::(\S+)', r'<div class="\1">\n', md) # convert ::: divs to <div>s
    md = re.sub(r':::', '\n</div>', md) # convert ::: divs to <div>s
    md = re.sub(r'\]\([^\)]*\)({[^}]*})?', ']', md) # remove links
    md = re.sub(r'`{\.\S+\}', '`', md) # remove inline code classes
    
    import mdformat
    out = mdformat.text(md, extensions={"gfm"}, options={"number":True, "wrap":width})
    
    out.count('[')
    
    return out.rstrip().replace('\n','\n'+' '*indent).replace(r'\[','[').replace(r'\]',']')

def yaml_str_helper(pfx, md, width=79):
    txt = tidy_markdown(md, len(pfx), width)
    if ('\n'+' '*len(pfx)+'\n') in txt: return pfx + '|\n' + ' '*len(pfx) + txt
    if ': ' in txt or txt.startswith('@'):
        if '"' in txt: return pfx + '|\n' + ' '*len(pfx) + txt
        else: return pfx+'"' + txt + '"'
    return pfx + txt



class CheckedDict[Key,Value](dict[Key,Value]):
  """A helper to make it easier to ensure there's not conflicts in the input files"""
  def add(self, key:Key, value:Value):
    """Ensures that self[key] == value,
    either by inserting the key or by asserting that that's its value"""
    if key in self: assert self[key] == value, f'Cannot change value of {key!r}'
    else: self[key] = value


class Concept:
  """A class embodying the "concepts" described by YAML files as defined in https://gedcom.io/terms/format
  Only the fields that are generated by the standard are included here; extension-specific like `extension tags`
  and not in the standard like `translated from` and `help text` are excluded for brevity."""
  
  lang: str
  type: typing.Literal["structure", "enumeration", "enumeration set", "calendar", "month", "data type"] # uri also allowed, but not provided in spec
  uri: str

  abnf_production: str|None
  calendars: list[str]
  enumeration_values: list[str]
  epochs: list[str]
  label: str|None
  months: list[str]
  spec: list[str]
  standard: bool|None
  tag: str|None
  subsumes: list[str]
  value_of: list[str]
  deprecated: bool

  def __init__(self, type, uri):
    self.lang = 'en-US'
    self.type = type
    self.uri = uri
    
    self.abnf_production = None
    self.calendars = []
    self.enumeration_values = []
    self.epochs = []
    self.label = None
    self.months = []
    self.spec = []
    self.standard = (self.type == 'enumeration set')
    self.tag = None
    self.subsumes = []
    self.value_of = []
    self.deprecated = False
    
  def set(self, name:str, value:str):
    """A helper to verify that information that has only one value is givne consistently across all instances."""
    assert name in self.__dict__, "Can only set known attributes"
    if self.__dict__[name] is None: self.__dict__[name] = value
    else: assert self.__dict__[name] == value, f"Only one value allowed for {name!r} of {self.uri}; was {self.__dict__[name]!r}, now {value!r}"


  def __str__(self) -> str:
    """Manual readable YAML generation. pyYAML doesn't have enough control to get the format we like so we do it manually."""
    ans = [
      '%YAML 1.2\n---\nlang: '+self.lang,
      'type: '+self.type,
      'uri: '+self.uri,
    ]

    if self.tag is not None: ans.append('standard tag: '+repr(self.tag))

    if self.abnf_production is not None: ans.append('abnf production: '+self.abnf_production)

    if len(self.spec) >= 0:
      spec = 'specification:'
      for i,entry in enumerate(self.spec):
        if self.spec.index(entry) < i: continue # remove duplicates
        spec += '\n'+yaml_str_helper('  - ', entry)
      if len(spec) > len('specification:'): ans.append(spec)

    if self.label is not None:
      if self.deprecated: ans.append('label: '+repr('(deprecated) '+self.label))
      else: ans.append('label: '+repr(self.label))
    
    ans.extend(self.type_specific())
    
    if any('/v7.1/' in item for item in ans):
      ans.append('prerelease: true')
    
    ans.append('contact: "https://gedcom.io/community/"\n...')
    return '\n\n'.join(ans)

  def type_specific(self) -> list[str]:
    ans = []

    simple = { # all lists or strings, no dicts
      'calendars': self.type == 'month',
      'enumeration_values': self.type == 'enumeration set',
      'months': self.type == 'calendar',
      'epochs': self.type == 'calendar',
      'standard': self.type == 'enumeration set',
      'subsumes':False,
      'value_of': self.type == 'enumeration',
    }
    for key,req in simple.items():
      val = self.__dict__[key]
      key = key.replace('_',' ')
      if not val and not req: continue
      if val is None: ans.append(key+': null')
      elif val == [] or isinstance(val, bool): ans.append(key+': '+str(val).lower())
      elif isinstance(val, str):
        assert '"' not in val and '\n' not in val, f"Simplified serialization failed for {uri}'s {key}"
        ans.append(key+': "'+val+'"')
      else:
        entry = key+':'
        for v in (sorted(val) if key != 'months' else val):
          assert '"' not in v and '\n' not in v, f"Simplified serialization failed for {uri}'s {key}"
          entry += '\n  - "'+v+'"'
        ans.append(entry)

    return ans
    

class StructData(Concept):
  """Information about one structure type"""
  sub: CheckedDict[str,str] # URI:cardinality
  sup: CheckedDict[str,str] # URI:cardinality
  pay: str|None
  enumset: str|None

  def __init__(self, uri):
    super().__init__('structure', uri)
    self.sub = CheckedDict()
    self.sup = CheckedDict()
    self.pay = None
    self.enumset = None

  def type_specific(self) -> list[str]:
    ans = []
    
    if self.pay is None: ans.append('payload: null')
    elif self.pay[0] == '@': ans.append('payload: "'+self.pay+'"')
    else: ans.append('payload: '+self.pay)
    
    if self.enumset is not None: ans.append('enumeration set: "'+self.enumset+'"') # quoted to match older version; other URI values are unquoted
    
    if len(self.sub) == 0: ans.append('substructures: {}')
    else: ans.append('substructures:\n  "' + '"\n  "'.join(k+'": "'+v for k,v in sorted(self.sub.items()))+'"')
      
    if len(self.sup) == 0: ans.append('superstructures: {}')
    else: ans.append('superstructures:\n  "' + '"\n  "'.join(k+'": "'+v for k,v in sorted(self.sup.items()))+'"')
    
    ans.extend(super().type_specific())
    
    return ans
    

class StructSet:
  """Information about many structures"""
  data: dict[str,StructData]

  def __init__(self):
    self.data = {}

  def __getitem__(self, uri:str) -> StructData:
    """Returns (and creates if necessary) a StructData for the given URI"""
    if uri not in self.data:
      self.data[uri] = StructData(uri)
    return self.data[uri]

  def subsup(self, sub:str, sup:str, card:str) -> None:
    """Helper to record substructure/superstructure relationships"""
    self[sub].sup.add(sup, card)
    self[sup].sub.add(sub, card)

  def parse_gedstruct(self, gs:str, pfx:dict[str,str]={}) -> None:
    """Given the concatenated gedstruct data (see extract-grammars.py),
    populates this StructSet with all of those structures.
    
    Populates only data available from gedstruct: tag, sub- and super-structure, abbreviated uri,
    and the payload type strings in gedstruct (e.g. <List:Enum> not that URI of that).
    """
    
    def mix_card(c1,c2):
      """Combines cardinalities: if I have {1:M} of something that is {0:1}, I actually have {0:M}, and so on."""
      return min(c1[:2],c2[:2]) + max(c1[2:], c2[2:])
    
    def do_pfx(uri):
      """Expands URI prefixes"""
      if not uri: return uri
      for short,long in pfx.items():
        if uri.startswith(short): return uri.replace(short, long, count=1)
      return uri

    # find top-level rules
    xrefs : dict[str,str] = {} # e.g. {"INDI":"g7:record-INDI"} because @XREF:INDI@ is for that record URI
    becomes : dict[str,dict[str,str]] = {} # e.g. {"NOTE_STRUTURE": {"g7:NOTE":"{1:1}"}}
    for m in re.finditer(r'(\S+) *:=\s*(\[\s*)?((?:^[^=]*$)*)', gs, flags=re.M):
      becomes[m[1]] = {}
      base_card = '{0:1}' if m[2] else '{1:1}' # handles [|] under the assumption that never realized as "either/or but not both"
      for m2 in re.finditer(r'^[0n] (?:@XREF:(\S+)@ )?(\S+)[^{}]*({.:.})(?: *(\S+))?', m[3], flags=re.M):
        becomes[m[1]][do_pfx(m2[4]) or m2[2]] = mix_card(base_card, m2[3])
        if m2[1]: xrefs[m2[1]] = do_pfx(m2[4])
    # resolve chains like EVENT_DETAIL -> <<PLACE_STRUCTURE>>
    for iterations in range(2): # longest chain is Dataset → <<RECORD>> → <<FAMILY_RECORD>>, 2 steps
      for key in becomes:
        for name in [k for k in becomes[key] if k.startswith('<<')]:
          c = becomes[key].pop(name)
          becomes[key].update({k:mix_card(c,v) for k,v in becomes[name[2:-2]].items()})
    
    # parse main gedstruct content
    stack : list[str] = [] # the smaller-level structures on the path to this line
    lines = re.split(r'[\r\n]+', gs)
    for line in lines:
      if ':=' in line: continue # header lines like "RECORD :=" handled as top-level rule above
      tok = line.strip().split()
      if len(tok) < 3: continue # blank line or one of [, |, ]: skip
      level = 0 if tok[0] == 'n' else int(tok[0])
      stack = stack[:level]
      if tok[1].startswith('@'): del tok[1] # remove the @XREF:INDI@ bits to make other parts line up
      
      if tok[1].startswith('<<'): # reference like   +1 <<NOTE_STRUCTURE>> {0:M}
        if level > 0:
          c = tok[-1]
          for uri,card in becomes[tok[1][2:-2]].items():
            self.subsup(uri, stack[-1], mix_card(c, card))
      
      else: # structure like   +1 TRAN <PersonalName> {1:M}  g7:NAME-TRAN
        uri = do_pfx(tok[-1])
        self[uri].tag = tok[1]
        if level > 0:
          self.subsup(uri, stack[-1], tok[-2])
        if len(tok) == 5: # level tag <payload> cardinality uri
          if tok[2].startswith('@<XREF:'):
            self[uri].pay = '@<'+xrefs[tok[2][7:-2]]+'>@'
          elif tok[2] == '[Y|<NULL>]':
            self[uri].pay = 'Y|<NULL>'
          else:
            self[uri].pay = tok[2]
        stack.append(uri)


def all_tables(txt:str) -> dict[str,list[dict[str,str]]]:
  """Finds all tables in the input
  Returns a dict {"section header text":[row, row, row]}
  where each row is {"header text":"cell entry"}.
  If the header has a <br> then so must the entries, and they'll be split as if separate columns.
  
  Assumes there will be at most one table per section
  """
  sect:str
  rowh:list[str]|None = None
  hcount = 0
  ans:dict[str,list[dict[str,str]]] = {}
  # for each section header or table row
  for m in re.finditer(r'^#+\s*([^\n]*)|(^[^\n]*\|[^\n]*\|[^\n]*)', txt, re.M):
    if m[1]: # section header
      sect = m[1]
      if '{' in sect: sect = sect[:sect.find('{')].strip()
      rowh = None
      hcount = 0
    elif rowh is None and m[2]: # first table row, and hence a header
      rowh = [s.strip() for s in m[2].strip('|').split('|')]
    else: # not-first table row
      cells = [s.strip() for s in m[2].strip('|').split('|')]
      if all(len(s.strip(' -:')) == 0 for s in cells): # header/body separator
        hcount += 1
        if verbose and hcount != 1:
          print('Section', sect, 'table number',hcount,'assumed to continue previous table')
        continue
      assert rowh is not None and len(cells) == len(rowh) # sanity check, ensure row length matches header
      entry = {k:v for k,v in zip(rowh,cells)}
      for k in (k for k in rowh if '<br' in k): # handle br in header and cell
        v = entry.pop(k)
        entry.update({k_:v_ for k_,v_ in zip(re.split(r'<br/?>', k), re.split(r'<br/?>', v))})
      ans.setdefault(sect,[]).append(entry)
  return ans


def all_uri_section_text(txt:str, pfx:dict[str,str], data:dict[str,Concept]) -> tuple[dict[str,str], dict[str,list[str]]]:
  """Finds all sections that are headed by a URI or URI-paired values.
  Adds them to the provided dict
  and returns 
  - a dict from datatype names (like List:Enum) to their URIs
  - a dict from table lables "event" and "attribute" to enumeration set URIs (like g7:enumset-EVENATTR) that include them
  """
  
  def do_pfx(uri:str) -> str:
    """Expands URI prefixes"""
    for short,long in pfx.items():
      if uri.startswith(short): return uri.replace(short, long, count=1)
    return uri

  types:dict[str,str] = {} # {"<List:Enum>": "g7:type-List#Enum"}
  enum_has:dict[str,list[str]] = {} # {"event": ["g7:enumset-EVENATTR", "g7:enumset-EVEN"]}
  aux:dict[str,str] = {}  # {"TRAN": text of the section about all TRAN-taged structures}
  
  # Loop through each markdown section
  bits = re.split(r'\s*^#+ *([^\n{]*)[^\n]*\s*', txt, flags=re.M)
  for header, section in zip(bits[1::2], bits[2::2]):
    # tidy up for easier regex:
    header = header.strip() # remove extra spaces
    #section = re.sub(r'\[([^\[\]]*)\](?:\([^()]*\))?(?:{[^{}]*})?', r'\1', section) # remove hyperlinks and classes

    # sections defining a structure have headers like   `TAG` (label) `uri`
    stm = re.fullmatch(r'`([^`]*)`\s*\(([^\)]*)\)\s*(?:`([^`]*)`)?', header)
    if stm:
      tag, label, uri = stm.groups()
      if uri is None: # A generic section applying to several related URIs, like TRAN
        aux[tag] = section
      else:
        uri = do_pfx(uri)
        assert uri in data, f"A section defines {uri} but it's not in a gedstruct block"
        assert isinstance(data[uri], StructData), f"A section defines {uri} as a struct, but it's a {data[uri].type} already"
        data[uri].set('tag', tag)
        data[uri].set('label', label)
        data[uri].spec.append(label)
        data[uri].spec.append(section)
        if tag in aux:
          data[uri].spec.append(aux[tag])
        enumset = re.search(r'enumerated values? from set `([^`]+)`', section)
        if enumset:
          data[uri].set('enumset', do_pfx(enumset[1]))
        if re.search(r':::deprecation\s+[^\n]*should not be added to new files', section):
          data[uri].deprecated = True

    # sections defining a major structure have headers like   `LONG_NAME` :=
    elif header.strip().endswith(':=') and header.strip().startswith('`'):
      rulename = header.strip('` :=')
      gedstruct = re.match(r'\s*```[^\n]*gedstruct[^\n]*([\s\S]*?)```+', section)
      assert gedstruct is not None, f'Expected section {repr(header)} to start with a gedstruct block'
      text = section[gedstruct.end():]
      for leveln in re.finditer(r'^n[^\n]+} +(\S+:\S+)', gedstruct[1], re.M):
        uri = do_pfx(leveln[1])
        assert uri in data, f"A section defines {uri} with a gedstruct block but it was missed in earlier gedstruct parsing"
        data[uri].spec.append(text)

    # sections defining a datatype have the text   The URI (of|for) the `NAME` data type is `uri`.
    elif re.search(r'The URI[^\n`]*`([^`]*)` data types? is `([^`]*)`', section):
      for dtd in re.finditer(r'The URI[^\n`]*`([^`]*)` data types? is `([^`]*)`', section):
        typename, uri = dtd[1], do_pfx(dtd[2])
        types['<'+typename+'>'] = uri
        if not uri.startswith('https://gedcom.io'): continue # not ours to define
        if uri not in data: data[uri] = Concept('data type', uri)
        data[uri].set('label', header)
        if re.search(f'^{typename.replace(':','-')} +=', section, flags=re.M):
          data[uri].set('abnf_production', typename.replace(':','-'))
        data[uri].spec.append(section)

    # sections defining a calendar have the text   The URI for this calendar is `uri`.
    elif 'The URI for this calendar is' in section:
      tag = header.strip('` ')
      epochs = re.findall(r'The epoch marker `([^`]+)` is permitted', section)
      uri = do_pfx(re.search(r'The URI for this calendar is `([^`]+)`', section)[1]) # type: ignore[index]
      if uri not in data: data[uri] = Concept('calendar', uri)
      data[uri].set('tag', tag)
      data[uri].epochs.extend(epochs)
      data[uri].spec.append(section)
      name = re.search(r'The ([^\n]*?) calendar', section)
      if name: data[uri].set('label', name[1])
      
    # sections defining an enumset have the headers like `uri` where the uri has enumset- in it
    elif re.fullmatch(r'\s*`[^`]*enumset-[^`]*`\s*', header):
      uri = do_pfx(header.strip('` '))
      if uri not in data: data[uri] = Concept('enumeration set', uri)
      asenum_line = re.search(r'^A[^\n]*-type tag name', section)
      if asenum_line:
        for word in re.findall(r'([a-z]*)-', asenum_line[0]):
          enum_has.setdefault(word,[]).append(uri)
      without_tables = re.sub(r'^\|[^\n]*\|$', '', section, flags=re.M).strip()
      if len(without_tables): data[uri].spec.append(without_tables)

    elif verbose:
      print('No URI defined in section:', header)

  return types, enum_has


if __name__ == '__main__':
  # configuration
  from pathlib import Path
  import argparse
  args_parser = argparse.ArgumentParser(description='Extracts YAML and TSV files from the specification markdown and the grammar.gedstruct generated by extract-grammars.py')
  args_parser.add_argument('-s', '--spec', default=Path('../specification'), type=Path, help='Directory containing gedcom*.md files')
  args_parser.add_argument('-d', '--dest', default=Path('../extracted-files'), type=Path, help='Directory in which to put payloads.tsv, tags/HEAD, and so on')
  args = args_parser.parse_args()
  
  # step 1: read the files
  src_gedstruct = open(Path(args.dest, 'grammar.gedstruct')).read()
  src_markdown = '\n\n'.join(open(s).read().replace('\xA0',' ') for s in args.spec.glob('gedcom*.md'))
  
  # step 2: find all tables and convert them to {section header: [{column header: column value}]}
  tables = all_tables(src_markdown)
  
  # step 3: extract the URI prefixes from the spec and make a function to expand them
  pfx = {row['Short Prefix'].strip('`')+':':row['URI Prefix'].strip('`') for row in tables['URIs and Prefix Notation']}
  def do_pfx(uri:str) -> str:
    """Expands URI prefixes"""
    for short,long in pfx.items():
      if uri.startswith(short): return uri.replace(short, long, count=1)
    return uri
  
  # step 4: parse everything we can from the gedstruct blocks
  structs = StructSet()
  structs['https://gedcom.io/terms/v7/CONT'].tag = 'CONT'
  structs.parse_gedstruct(src_gedstruct, pfx)
  data:dict[str,Concept] = {}
  data.update(structs.data) # copy, not alias, because `structs` will break if other Concepts included
  
  # step 5: parse the big blocks of text and non-structure URI definitions from the spec
  types, enum_has = all_uri_section_text(src_markdown, pfx, data)
  
  # step 6: beause we did 4 before 5 (which made both steps easier), we need to change payload types to URIs
  for s in data.values():
    if isinstance(s, StructData):
      if s.pay in types:
        s.pay = types[s.pay]
      elif s.pay is not None:
        assert s.pay == 'Y|<NULL>' or s.pay.startswith('@<http'), "Unexpected payload type "+repr(s.pay)

  # step 7: add in other information stored in the tables we found in step 2
  for sect, table in tables.items():
    # 7.a: sections with enumset URI headers define most of the set in 
    eset = ':enumset-' in sect
    if eset:
      sect = do_pfx(sect.strip('`'))
      assert sect in data, "Enumeration sets should have been found by all_uri_section_text"
      assert data[sect].type == 'enumeration set', f"{sect} is expected to the an enumeration set, not a {data[sect].type}"
    
    # 7.b: see if this section needs to be copied into any other enumsets
    putin = []
    for word in enum_has:
      if sect.lower().endswith(word+'s'):
        putin.extend(enum_has[word])
    
    for row in table:
      if 'URI' not in row: continue
      uri = do_pfx(row['URI'].strip('`'))

      # 7.c: pairing enumerations with their enumsets
      if eset: 
        if uri not in data:
          data[uri] = Concept('enumeration', uri)
        data[sect].enumeration_values.append(uri)
        data[uri].value_of.append(sect)
        data[uri].set('tag',row['Value'].strip(' `'))
      
      # 7.d: pairing months with calendars
      if '/month-' in uri:
        assert uri not in data, f"This script assumes months are not found before this point, but {uri} was"
        data[uri] = Concept('month', uri)
        caluri = re.sub(r'/month-.*', '/cal-'+sect.strip('` '), uri)
        assert caluri in data, f"This script uses a heuristic to find the calender of a month, but it failed for {uri} ({caluri} is wrong)."
        data[uri].calendars.append(caluri)
        data[caluri].months.append(uri)

      assert uri in data, f"Table entry for {uri} not in data yet"
      
      # 7.e: common values (tags, labels, specification) in many tables
      for k,v in row.items():
        if k in ('Tag','Value','`stdTag`'): data[uri].set('tag', v.strip('` '))
        elif k in ('Description','Meaning','Name'):
          data[uri].spec.append(v)
          if k == 'Name' and not data[uri].label:
            if ', or ' in v: v = v[:v.find(', ')]
            elif ' or ' in v: v = v[:v.find(' or ')]
            if '(' in v: v = v[:v.find('(')]
            data[uri].label = v.strip()
        elif k in ('Status', 'Applies to'): data[uri].spec.append(k+': '+v)
      
      # 7.f: the anomalous "event- or attribute-type tag name" enumsets
      for copyto in putin:
        data[copyto].enumeration_values.append(uri)
        if copyto not in data[uri].value_of: data[uri].value_of.append(copyto)

  # step 8: an enumset can only have one URI with each tag; if there's several and one is named .../enum-SOMETHING, it wins; otherwise if there's several it's an error
  for uri,thing in data.items():
    if thing.type != 'enumeration set': continue
    bytag : dict[str,list[str]] = {}
    for value in thing.enumeration_values:
      bytag.setdefault(data[value].tag, []).append(value) # type: ignore[arg-type]
    for tag,uris in bytag.items():
      if len(uris) <= 1: continue
      best = [u for u in uris if '/enum-' in u]
      assert len(best) == 1, "Conflicting enumeration values with no winner: "+uri+" has "+str(uris)
      for u in uris:
        if u != best[0]:
          thing.enumeration_values.remove(u)
          data[u].value_of.remove(uri)
  
  # step 9: hard-coded special case: JULIAN and GREGORIAN share months
  for month in data['https://gedcom.io/terms/v7/cal-GREGORIAN'].months:
    data['https://gedcom.io/terms/v7/cal-JULIAN'].months.append(month)
    data[month].calendars.append('https://gedcom.io/terms/v7/cal-JULIAN')

  # step 10: compute file paths and handle URIs with hashtags
  for uri in tuple(data):
    if not uri.startswith('https://gedcom.io'): del data[uri]
  pathof = {uri: str(args.dest)+'/tags'+uri[uri.rfind('/'):].replace('#','-') for uri in data}

  # step 11: add subsumes for any URI that also exists in earlier minor version
  from subprocess import run
  for uri in data:
    if '/v7.1/' in uri:
      res = run(['git','show','main:'+pathof[uri]], capture_output=True) # HACK, fix me
      if not res.returncode:
        data[uri].subsumes.append(uri.replace('/v7.1/', '/v7/'))

  # step 12: write all the various files

  # 12.a: YAML files
  for uri in data:
    with open(pathof[uri], 'w') as dst:
      print(data[uri], file=dst)

  # 12.b: superstructure substructure cadinality
  with open(Path(args.dest, "cardinalities.tsv"), 'w') as dst:
    for uri,s in sorted(data.items()):
      if isinstance(s, StructData):
        for sup,card in sorted(s.sup.items()):
          print(f'{sup}\t{uri}\t{card}', file=dst)

  # 12.c: enumeration_set enumeration_value
  with open(Path(args.dest, "enumerationsets.tsv"), 'w') as dst:
    for uri,s in sorted(data.items()):
      if s.type == 'enumeration set':
        for u in sorted(s.enumeration_values):
          print(f'{uri}\t{u}', file=dst)

  # 12.d: structure enumeration_set
  with open(Path(args.dest, "enumerations.tsv"), 'w') as dst:
    for uri,s in sorted(data.items()):
      if isinstance(s, StructData):
        if s.enumset:
          print(f'{uri}\t{s.enumset}', file=dst)

  # 12.e: structure payload
  with open(Path(args.dest, "payloads.tsv"), 'w') as dst:
    for uri,s in sorted(data.items()):
      if isinstance(s, StructData):
        print(f'{uri}\t{s.pay or ''}', file=dst)

  # 12.f: superstructure tag substructure
  with open(Path(args.dest, "substructures.tsv"), 'w') as dst:
    for uri,s in sorted(data.items()):
      if isinstance(s, StructData):
        for sup,card in sorted(s.sup.items()):
          print(f'{sup}\t{s.tag}\t{uri}', file=dst)
        if len(s.sup) == 0:
          print(f'\t{s.tag}\t{uri}', file=dst)
